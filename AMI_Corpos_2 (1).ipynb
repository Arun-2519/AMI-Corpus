{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =================== CELL 1: INSTALLS ===================\n",
        "!pip install -q transformers==4.40.0 datasets sentence-transformers nltk scikit-learn sacrebleu rouge_score sentencepiece accelerate safetensors\n",
        "\n",
        "print(\"Installs done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbY4UFbuvYcG",
        "outputId": "b5805892-a775-433f-9bf4-cd29d75e5bf5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installs done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =================== CELL 2: USER PATHS & FLAGS ===================\n",
        "import os, glob, zipfile, json, shutil, uuid, subprocess, sys, re, math\n",
        "from tqdm import tqdm\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# -----------------------\n",
        "# FLAGS / USER OPTIONS\n",
        "# -----------------------\n",
        "DO_EXTRACT_IF_ZIP_FOUND = True\n",
        "DO_TRAIN_LORA = False   # leave False (LoRA code optional)\n",
        "DO_EVAL = False\n",
        "\n",
        "FORCE_EXTRACTIVE_PRED = False\n",
        "\n",
        "# -----------------------\n",
        "# USER PATHS - change these if needed\n",
        "# -----------------------\n",
        "AMI_ZIP = \"/content/ami_public_manual_1.6.2.zip\"\n",
        "AMI_ROOT = \"/content/ami_corpus_manual\"\n",
        "TRANSCRIPT_FILE = \"/content/ami_corpus_manual/words/ES2009d.A.words.xml\"\n",
        "ABSSUM_FILE = \"/content/ami_corpus_manual/abstractive/ES2002a.abssumm.xml\"\n",
        "OUT_DIR = \"/content/ami_project_out\"\n",
        "\n",
        "# Derived\n",
        "LORE_DIR = os.path.join(OUT_DIR, \"flan_t5_lora_ami\")\n",
        "TEXT_SUM_DIR = os.path.join(OUT_DIR, \"ami_summaries_txt\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(TEXT_SUM_DIR, exist_ok=True)\n",
        "\n",
        "print(\"USER PATHS:\")\n",
        "print(\"AMI_ZIP:\", AMI_ZIP)\n",
        "print(\"AMI_ROOT:\", AMI_ROOT)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n",
        "# =================== CELL 3: HELPERS & AUTO-LOCATE ZIP ===================\n",
        "def safe_print_header(msg):\n",
        "    print(\"\\n\" + \"=\"*6 + \" \" + msg + \" \" + \"=\"*6)\n",
        "\n",
        "def try_extract_zip_to(zip_path, target_dir):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "            z.extractall(target_dir)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"Zip extraction failed:\", e)\n",
        "        return False\n",
        "\n",
        "def find_file_by_basename(basename, search_root=\"/content\"):\n",
        "    matches = sorted(glob.glob(os.path.join(search_root, \"**\", basename), recursive=True))\n",
        "    return matches[0] if matches else None\n",
        "\n",
        "safe_print_header(\"FILE CHECK & AUTO-LOCATE\")\n",
        "print(\"Trying to locate AMI files...\")\n",
        "\n",
        "transcript_exists = os.path.exists(TRANSCRIPT_FILE)\n",
        "abssum_exists = os.path.exists(ABSSUM_FILE)\n",
        "\n",
        "if not transcript_exists:\n",
        "    c = find_file_by_basename(os.path.basename(TRANSCRIPT_FILE), \"/content\")\n",
        "    if c:\n",
        "        TRANSCRIPT_FILE = c; transcript_exists = True; print(\"Located transcript:\", c)\n",
        "if not abssum_exists:\n",
        "    c = find_file_by_basename(os.path.basename(ABSSUM_FILE), \"/content\")\n",
        "    if c:\n",
        "        ABSSUM_FILE = c; abssum_exists = True; print(\"Located abstractive summary:\", c)\n",
        "\n",
        "if (not transcript_exists or not abssum_exists) and DO_EXTRACT_IF_ZIP_FOUND and os.path.exists(AMI_ZIP):\n",
        "    print(\"AMI zip exists — extracting to\", AMI_ROOT)\n",
        "    if try_extract_zip_to(AMI_ZIP, AMI_ROOT):\n",
        "        c = find_file_by_basename(os.path.basename(TRANSCRIPT_FILE), AMI_ROOT)\n",
        "        if c: TRANSCRIPT_FILE = c; transcript_exists = True; print(\"Found transcript after extract:\", c)\n",
        "        c = find_file_by_basename(os.path.basename(ABSSUM_FILE), AMI_ROOT)\n",
        "        if c: ABSSUM_FILE = c; abssum_exists = True; print(\"Found abssum after extract:\", c)\n",
        "\n",
        "print(\"Final exists -> transcript:\", os.path.exists(TRANSCRIPT_FILE), \"| abssum:\", os.path.exists(ABSSUM_FILE))\n",
        "if not (os.path.exists(TRANSCRIPT_FILE) and os.path.exists(ABSSUM_FILE)):\n",
        "    print(\"WARNING: Required file(s) missing. The pipeline can still search inside AMI_ROOT or exit.\")\n",
        "# =================== CELL 4: XML PARSERS ===================\n",
        "safe_print_header(\"PARSERS\")\n",
        "def tag_name(elem):\n",
        "    t = elem.tag\n",
        "    if isinstance(t, str) and '}' in t:\n",
        "        return t.split('}',1)[1].lower()\n",
        "    return str(t).lower()\n",
        "\n",
        "def parse_abssumm_xml(path):\n",
        "    if not path or not os.path.exists(path):\n",
        "        print(\"Abstractive summary file missing:\", path); return \"\"\n",
        "    try:\n",
        "        tree = ET.parse(path); root = tree.getroot()\n",
        "    except Exception as e:\n",
        "        print(\"Parse error (summary):\", e); return \"\"\n",
        "    texts=[]\n",
        "    candidates = ['abssumm','abstractive','abstract','summary','s','p']\n",
        "    for elem in root.iter():\n",
        "        tag = tag_name(elem)\n",
        "        for c in candidates:\n",
        "            if tag.endswith(c):\n",
        "                if elem.text and elem.text.strip(): texts.append(elem.text.strip())\n",
        "                for ch in elem:\n",
        "                    if ch.text and ch.text.strip(): texts.append(ch.text.strip())\n",
        "    if not texts:\n",
        "        def rec(el):\n",
        "            if el.text and el.text.strip(): texts.append(el.text.strip())\n",
        "            for ch in el: rec(ch)\n",
        "        rec(root)\n",
        "    return \" \".join(texts).strip()\n",
        "\n",
        "def parse_words_xml_speaker_turns(path):\n",
        "    if not path or not os.path.exists(path):\n",
        "        print(\"Transcript file missing:\", path); return []\n",
        "    try:\n",
        "        tree = ET.parse(path); root = tree.getroot()\n",
        "    except Exception as e:\n",
        "        print(\"Parse error (words):\", e); return []\n",
        "    turns=[]\n",
        "    for u in root.iter():\n",
        "        tag = tag_name(u)\n",
        "        if tag.endswith('u') or tag.endswith('turn') or 'segment' in tag or 'utterance' in tag:\n",
        "            speaker = u.attrib.get('who') or u.attrib.get('pname') or u.attrib.get('speaker') or \"UNK\"\n",
        "            parts=[]; start=None; end=None\n",
        "            for w in u.iter():\n",
        "                wt = (w.text or \"\").strip()\n",
        "                if wt: parts.append(wt)\n",
        "                s = w.attrib.get('starttime') or w.attrib.get('stime') or w.attrib.get('start')\n",
        "                e = w.attrib.get('endtime') or w.attrib.get('etime') or w.attrib.get('end')\n",
        "                if s and start is None:\n",
        "                    try: start=float(s)\n",
        "                    except: pass\n",
        "                if e:\n",
        "                    try: end=float(e)\n",
        "                    except: pass\n",
        "            text = \" \".join(parts).strip()\n",
        "            if text:\n",
        "                turns.append({\"speaker\":speaker,\"start\":start,\"end\":end,\"text\":text})\n",
        "    if not turns:\n",
        "        tokens=[]\n",
        "        for elem in root.iter():\n",
        "            if tag_name(elem).endswith('w'):\n",
        "                t=(elem.text or \"\").strip()\n",
        "                if t: tokens.append(t)\n",
        "        if tokens:\n",
        "            turns=[{\"speaker\":\"UNK\",\"start\":None,\"end\":None,\"text\":\" \".join(tokens)}]\n",
        "    return turns\n",
        "# =================== CELL 5: BUILD PAIRS ===================\n",
        "safe_print_header(\"BUILD PAIRS\")\n",
        "pairs=[]\n",
        "if os.path.exists(TRANSCRIPT_FILE) and os.path.exists(ABSSUM_FILE):\n",
        "    summary_text = parse_abssumm_xml(ABSSUM_FILE)\n",
        "    turns = parse_words_xml_speaker_turns(TRANSCRIPT_FILE)\n",
        "    dialogue_tagged = \"\\n\".join([f\"[{t['speaker']}] {t['text']}\" for t in turns])\n",
        "    dialogue_raw = \" \".join([t['text'] for t in turns])\n",
        "    if summary_text and (dialogue_raw or dialogue_tagged):\n",
        "        pairs.append({\"meeting_id\": os.path.basename(TRANSCRIPT_FILE).split('.')[0],\n",
        "                      \"dialogue\": dialogue_raw,\n",
        "                      \"dialogue_tagged\": dialogue_tagged,\n",
        "                      \"turns\": turns,\n",
        "                      \"summary\": summary_text})\n",
        "        print(\"Built 1 pair from provided files.\")\n",
        "    else:\n",
        "        print(\"Parsed summary or transcript is empty; skipping.\")\n",
        "else:\n",
        "    if os.path.exists(AMI_ROOT):\n",
        "        found_summaries = sorted(glob.glob(os.path.join(AMI_ROOT,\"**\",\"*.abssumm.xml\"), recursive=True) + glob.glob(os.path.join(AMI_ROOT,\"**\",\"*abstractive*.xml\"), recursive=True))\n",
        "        found_transcripts = sorted(glob.glob(os.path.join(AMI_ROOT,\"**\",\"*.words.xml\"), recursive=True))\n",
        "        if found_summaries and found_transcripts:\n",
        "            def meeting_id_from_path(p):\n",
        "                bn=os.path.basename(p)\n",
        "                m=re.search(r\"([A-Z]{2}\\d{4}[a-d]?)\",bn)\n",
        "                if m: return m.group(1)\n",
        "                return os.path.splitext(bn)[0]\n",
        "            trans_map = {meeting_id_from_path(p): p for p in found_transcripts}\n",
        "            for s in found_summaries:\n",
        "                mid = meeting_id_from_path(s); t = trans_map.get(mid)\n",
        "                if t:\n",
        "                    summary_text = parse_abssumm_xml(s)\n",
        "                    turns = parse_words_xml_speaker_turns(t)\n",
        "                    dialogue_tagged = \"\\n\".join([f\"[{tt['speaker']}] {tt['text']}\" for tt in turns])\n",
        "                    dialogue_raw = \" \".join([tt['text'] for tt in turns])\n",
        "                    if summary_text and (dialogue_raw or dialogue_tagged):\n",
        "                        pairs.append({\"meeting_id\":mid,\"dialogue\":dialogue_raw,\"dialogue_tagged\":dialogue_tagged,\"turns\":turns,\"summary\":summary_text})\n",
        "            if pairs:\n",
        "                print(f\"Built {len(pairs)} pair(s) from AMI_ROOT fallback search.\")\n",
        "            else:\n",
        "                print(\"Could not pair found files.\")\n",
        "        else:\n",
        "            print(\"No suitable files found under AMI_ROOT.\")\n",
        "    else:\n",
        "        print(\"AMI_ROOT missing:\", AMI_ROOT)\n",
        "\n",
        "if pairs:\n",
        "    with open(os.path.join(OUT_DIR,\"ami_pairs_preview.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(pairs[:5], f, ensure_ascii=False, indent=2)\n",
        "    print(\"Saved preview ->\", os.path.join(OUT_DIR,\"ami_pairs_preview.json\"))\n",
        "else:\n",
        "    print(\"No pairs created. Skipping pipeline.\")\n",
        "# =================== CELL 6: NLTK punkt download & SBERT optional ===================\n",
        "safe_print_header(\"SETUP NLP DEPENDENCIES\")\n",
        "import nltk\n",
        "# download punkt; if network prevents it, we'll fallback later\n",
        "try:\n",
        "    nltk.download('punkt', quiet=False)\n",
        "except Exception as e:\n",
        "    print(\"NLTK punkt download failed (will use fallback sentence splitter):\", e)\n",
        "\n",
        "# safe sentence tokenizer function (uses nltk if available, otherwise simple regex)\n",
        "import re\n",
        "def safe_sent_tokenize(text):\n",
        "    try:\n",
        "        from nltk.tokenize import sent_tokenize as _nltk_sent\n",
        "        return _nltk_sent(text)\n",
        "    except Exception:\n",
        "        # fallback: naive split on sentence-ending punctuation\n",
        "        parts = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "        parts = [p.strip() for p in parts if len(p.strip())>0]\n",
        "        return parts\n",
        "\n",
        "# Try to load SBERT (optional)\n",
        "sbert_model = None\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    import torch\n",
        "    device_sbert = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device_sbert)\n",
        "    print(\"Loaded SBERT on device:\", device_sbert)\n",
        "except Exception as e:\n",
        "    print(\"SBERT unavailable or failed to load:\", e)\n",
        "    sbert_model = None\n",
        "# =================== CELL 7: Extractive helpers, cleaning, scoring ===================\n",
        "safe_print_header(\"EXTRACTIVE CLEANING HELPERS\")\n",
        "def sent_tokenize_safe(text):\n",
        "    return safe_sent_tokenize(text)\n",
        "\n",
        "FILLERS_RE = re.compile(r\"\\b(um+|uh+|erm+|ah+|you know|i mean|like|sort of|kind of|okay|ok|so)\\b\", flags=re.I)\n",
        "MULTI_SPACE_RE = re.compile(r\"\\s{2,}\")\n",
        "KEYWORDS = [\n",
        "    \"decide\", \"decision\", \"decided\", \"action\", \"task\", \"assign\", \"deadline\", \"due\", \"will\",\n",
        "    \"agree\", \"agreed\", \"approve\", \"approved\", \"budget\", \"cost\", \"price\", \"deliver\", \"deliverable\",\n",
        "    \"complete by\", \"milestone\", \"requirement\", \"require\", \"responsible\", \"owner\", \"follow up\",\n",
        "    \"follow-up\", \"todo\", \"to-do\", \"estimate\", \"risk\", \"issue\", \"deliverable\", \"deadline\", \"schedule\"\n",
        "]\n",
        "NUMERIC_RE = re.compile(r\"\\b(\\d{1,4}(?:[.,]\\d{1,3})?|\\d+%|\\b\\d+\\b)\\b\")\n",
        "CURRENCY_RE = re.compile(r\"\\b(€|\\$|usd|eur|inr|rs|rupees|pound|£)\\b\", flags=re.I)\n",
        "DATE_WORDS = re.compile(r\"\\b(today|tomorrow|monday|tuesday|wednesday|thursday|friday|saturday|sunday|jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|week|month|year)\\b\", flags=re.I)\n",
        "\n",
        "def clean_sentence(text):\n",
        "    s = text.strip()\n",
        "    s = FILLERS_RE.sub(\"\", s)\n",
        "    s = re.sub(r\"[,;:\\-]{2,}\", \",\", s)\n",
        "    s = MULTI_SPACE_RE.sub(\" \", s)\n",
        "    s = s.strip(\" ,.;:-\")\n",
        "    s = re.sub(r\"\\b(\\w+)\\s+\\1\\b\", r\"\\1\", s)\n",
        "    if len(s.split()) < 3:\n",
        "        return \"\"\n",
        "    return s\n",
        "\n",
        "def rule_score_sentence(text):\n",
        "    low = text.lower()\n",
        "    score = 0.0\n",
        "    for kw in KEYWORDS:\n",
        "        if kw in low:\n",
        "            score += 1.8\n",
        "    if NUMERIC_RE.search(text):\n",
        "        score += 1.0\n",
        "    if CURRENCY_RE.search(text):\n",
        "        score += 1.2\n",
        "    if DATE_WORDS.search(text):\n",
        "        score += 0.8\n",
        "    if len(text.split()) < 4:\n",
        "        score -= 0.6\n",
        "    if text.strip().endswith(\"?\") and not any(kw in low for kw in KEYWORDS):\n",
        "        score -= 0.5\n",
        "    if re.search(r\"\\b(will|must|should|need|required|deliver|deliverable|due)\\b\", low):\n",
        "        score += 0.6\n",
        "    return score\n",
        "\n",
        "def extract_key_points_chronological_clean(turns, top_k=12, min_score=1.0):\n",
        "    chronological = []\n",
        "    for t in turns:\n",
        "        sents = sent_tokenize_safe(t.get(\"text\",\"\"))\n",
        "        for s in sents:\n",
        "            s_cleaned = clean_sentence(s)\n",
        "            if not s_cleaned:\n",
        "                continue\n",
        "            score = rule_score_sentence(s_cleaned)\n",
        "            if re.search(r\"\\b(i will|we will|I'll|we will|i'll|we'll)\\b\", s_cleaned, flags=re.I):\n",
        "                score += 0.6\n",
        "            chronological.append({\"speaker\": t.get(\"speaker\",\"UNK\"), \"start\": t.get(\"start\"), \"text\": s_cleaned, \"score\": round(score,3)})\n",
        "    picked = [p for p in chronological if p[\"score\"] >= min_score]\n",
        "    if len(picked) == 0:\n",
        "        sorted_by_score = sorted(chronological, key=lambda x: (x[\"score\"], len(x[\"text\"])), reverse=True)\n",
        "        candidates = sorted_by_score[:top_k]\n",
        "        # maintain original order\n",
        "        idx_map = {id(x): i for i,x in enumerate(chronological)}\n",
        "        picked = sorted(candidates, key=lambda x: idx_map[id(x)])\n",
        "    else:\n",
        "        picked = picked[:top_k]\n",
        "    return picked\n",
        "\n",
        "def format_extractive_points_chronological(points):\n",
        "    lines=[]\n",
        "    for p in points:\n",
        "        start = f\"{p['start']:.1f}s\" if p['start'] is not None else \"?\"\n",
        "        lines.append(f\"[{p['speaker']}] (at {start}): {p['text']}\")\n",
        "    return \"\\n\".join(lines)\n",
        "# =================== CELL 8: Tokenizer chunking helpers (safe by sentence) ===================\n",
        "safe_print_header(\"TOKENIZER CHUNK HELPERS\")\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def get_tokenizer(model_name=\"google/flan-t5-base\"):\n",
        "    tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "    if not hasattr(tok, \"model_max_length\") or tok.model_max_length is None or tok.model_max_length > 1_000_000_000:\n",
        "        tok.model_max_length = 512\n",
        "    return tok\n",
        "\n",
        "def chunk_text_by_tokenizer_safe(text, tokenizer_obj, max_tokens=None, stride=0):\n",
        "    \"\"\"\n",
        "    Break text into chunks that respect tokenizer_obj.model_max_length.\n",
        "    We split text into sentences, then package sentences into chunks while\n",
        "    checking token length on per-sentence basis. This avoids encoding huge full text.\n",
        "    \"\"\"\n",
        "    if tokenizer_obj is None:\n",
        "        # fallback: naive sentence chunks\n",
        "        sents = sent_tokenize_safe(text)\n",
        "        out=[]\n",
        "        cur=[]\n",
        "        cur_len=0\n",
        "        limit = max_tokens or 512\n",
        "        for s in sents:\n",
        "            l = len(s.split())\n",
        "            if cur_len + l > limit:\n",
        "                out.append(\" \".join(cur))\n",
        "                cur=[s]; cur_len=l\n",
        "            else:\n",
        "                cur.append(s); cur_len += l\n",
        "        if cur: out.append(\" \".join(cur))\n",
        "        return out\n",
        "\n",
        "    sents = sent_tokenize_safe(text)\n",
        "    max_m = max_tokens if max_tokens else (tokenizer_obj.model_max_length - 32)\n",
        "    chunks=[]\n",
        "    cur_ids_count = 0\n",
        "    cur_ids = []\n",
        "    cur_sents = []\n",
        "    for s in sents:\n",
        "        if not s.strip(): continue\n",
        "        # encode sentence alone to measure tokens (short)\n",
        "        ids = tokenizer_obj(s, add_special_tokens=False)[\"input_ids\"]\n",
        "        l = len(ids)\n",
        "        if l > max_m:\n",
        "            # sentence itself longer than max — force-split by words (rare)\n",
        "            words = s.split()\n",
        "            tmp=[]\n",
        "            tmp_count=0\n",
        "            for w in words:\n",
        "                w_ids = tokenizer_obj(w, add_special_tokens=False)[\"input_ids\"]\n",
        "                wc = len(w_ids)\n",
        "                if tmp_count + wc > max_m:\n",
        "                    if tmp: chunks.append(\" \".join(tmp))\n",
        "                    tmp=[w]; tmp_count = wc\n",
        "                else:\n",
        "                    tmp.append(w); tmp_count += wc\n",
        "            if tmp: chunks.append(\" \".join(tmp))\n",
        "            # reset current\n",
        "            cur_ids_count = 0; cur_ids = []; cur_sents=[]\n",
        "            continue\n",
        "        # if adding this sentence exceeds max, flush current chunk\n",
        "        if cur_ids_count + l > max_m:\n",
        "            chunks.append(\" \".join(cur_sents))\n",
        "            # prepare new chunk (with overlap/stride if desired)\n",
        "            if stride>0:\n",
        "                # keep last few sents for overlap (not implemented fully here to keep simple)\n",
        "                cur_sents = [s]\n",
        "                cur_ids_count = l\n",
        "            else:\n",
        "                cur_sents = [s]\n",
        "                cur_ids_count = l\n",
        "        else:\n",
        "            cur_sents.append(s)\n",
        "            cur_ids_count += l\n",
        "    if cur_sents:\n",
        "        chunks.append(\" \".join(cur_sents))\n",
        "    return chunks\n",
        "# =================== CELL 9: Extractive clustering helper (SBERT optional) ===================\n",
        "safe_print_header(\"EXTRACTIVE CLUSTERING (SBERT optional)\")\n",
        "def extractive_by_clustering(text, num_sentences=6):\n",
        "    try:\n",
        "        if sbert_model is None:\n",
        "            raise Exception(\"SBERT missing\")\n",
        "        sents = sent_tokenize_safe(text)\n",
        "        if len(sents) <= num_sentences:\n",
        "            return \" \".join(sents)\n",
        "        emb = sbert_model.encode(sents, convert_to_numpy=True, show_progress_bar=False)\n",
        "        from sklearn.cluster import KMeans\n",
        "        import numpy as np\n",
        "        k = min(num_sentences, len(sents))\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42).fit(emb)\n",
        "        centers = kmeans.cluster_centers_\n",
        "        chosen=[]\n",
        "        for c in centers:\n",
        "            idx=int(((emb-c)**2).sum(axis=1).argmin())\n",
        "            chosen.append((idx, sents[idx]))\n",
        "        chosen = sorted(chosen, key=lambda x:x[0])\n",
        "        return \" \".join([c for _,c in chosen])\n",
        "    except Exception:\n",
        "        return \" \".join(text.split(\".\")[:num_sentences])\n",
        "# =================== CELL 10: Prepare examples (extractive) ===================\n",
        "safe_print_header(\"PREPARE EXAMPLES\")\n",
        "tokenizer = None\n",
        "try:\n",
        "    tokenizer = get_tokenizer(\"google/flan-t5-base\")\n",
        "    print(\"Tokenizer model_max_length:\", tokenizer.model_max_length)\n",
        "except Exception as e:\n",
        "    print(\"Tokenizer load failed:\", e)\n",
        "    tokenizer = None\n",
        "\n",
        "def create_training_examples(pairs_list, tokenizer_obj=None, chunk_tokens=None):\n",
        "    examples={\"input_texts\":[],\"target_texts\":[]}\n",
        "    for p in pairs_list:\n",
        "        prefix=\"Summarize this meeting. Preserve speaker attribution.\\n\\n\"\n",
        "        if tokenizer_obj:\n",
        "            chunks = chunk_text_by_tokenizer_safe(p[\"dialogue_tagged\"], tokenizer_obj, max_tokens=chunk_tokens or (tokenizer_obj.model_max_length-32))\n",
        "        else:\n",
        "            chunks=[p[\"dialogue_tagged\"]]\n",
        "        chunk_summaries=[extractive_by_clustering(ch, num_sentences=5) for ch in chunks]\n",
        "        combined_input=prefix + \"\\n\\n\".join(chunk_summaries)\n",
        "        examples[\"input_texts\"].append(combined_input)\n",
        "        examples[\"target_texts\"].append(p[\"summary\"])\n",
        "    return examples\n",
        "\n",
        "train_examples = create_training_examples(pairs, tokenizer, chunk_tokens=512)\n",
        "print(\"Prepared\", len(train_examples[\"input_texts\"]), \"example(s).\")\n",
        "\n",
        "\n",
        "# =================== CELL 11: LoRA placeholder ===================\n",
        "safe_print_header(\"LoRA (optional)\")\n",
        "print(\"LoRA disabled by default (DO_TRAIN_LORA = False). Enable & configure if you want adapter training.\")\n",
        "\n",
        "\n",
        "# =================== CELL 12: MODEL LOADING & INFERENCE (safe chunking) ===================\n",
        "safe_print_header(\"INFERENCE & CHRONOLOGICAL EXTRACTION\")\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "MODEL_DIR = LORE_DIR if os.path.exists(LORE_DIR) else \"google/flan-t5-base\"\n",
        "\n",
        "try:\n",
        "    tokenizer = get_tokenizer(MODEL_DIR if os.path.exists(MODEL_DIR) else \"google/flan-t5-base\")\n",
        "except Exception as e:\n",
        "    print(\"Fallback tokenizer load failed:\", e)\n",
        "    tokenizer = get_tokenizer(\"google/flan-t5-base\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "try:\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_DIR).to(device)\n",
        "    model.eval()\n",
        "except Exception as e:\n",
        "    print(\"Model load failed:\", e)\n",
        "    model = None\n",
        "\n",
        "def run_abstractive(prompt_text, max_len=200):\n",
        "    if model is None or tokenizer is None:\n",
        "        return \"\"\n",
        "    # chunk prompt into safe-sized chunks\n",
        "    max_in = tokenizer.model_max_length - 32\n",
        "    chunks = chunk_text_by_tokenizer_safe(prompt_text, tokenizer, max_tokens=max_in)\n",
        "    preds=[]\n",
        "    for ch in chunks:\n",
        "        inputs = tokenizer(ch, return_tensors=\"pt\", truncation=True, max_length=min(max_in, tokenizer.model_max_length)).to(device)\n",
        "        try:\n",
        "            out = model.generate(**inputs, max_length=max_len, num_beams=4, early_stopping=True)\n",
        "            preds.append(tokenizer.decode(out[0], skip_special_tokens=True))\n",
        "        except Exception as e:\n",
        "            print(\"Generation error for chunk:\", e)\n",
        "            preds.append(\"\")\n",
        "    return \" \".join([p for p in preds if p]).strip()\n",
        "\n",
        "# =================== CELL 13: RUN INFERENCE & SAVE (fixed) ===================\n",
        "safe_print_header(\"RUN INFERENCE & SAVE\")\n",
        "inference_results = []\n",
        "for p in tqdm(pairs, desc=\"process-meetings\"):\n",
        "    prefix=\"Summarize this meeting. Preserve speaker attribution.\\n\\n\"\n",
        "    if tokenizer:\n",
        "        chunks = chunk_text_by_tokenizer_safe(p[\"dialogue_tagged\"], tokenizer, max_tokens=min(1024, tokenizer.model_max_length-32))\n",
        "    else:\n",
        "        chunks = [p[\"dialogue_tagged\"]]\n",
        "    chunk_summaries = [extractive_by_clustering(ch, num_sentences=5) for ch in chunks]\n",
        "    combined_input = prefix + \"\\n\\n\".join(chunk_summaries)\n",
        "\n",
        "    model_pred = \"\"\n",
        "    try:\n",
        "        model_pred = run_abstractive(combined_input, max_len=300)\n",
        "    except Exception as e:\n",
        "        print(\"Model generation failed:\", e)\n",
        "        model_pred = \"\"\n",
        "\n",
        "    if not model_pred:\n",
        "        model_pred = \" \".join(chunk_summaries[:3])\n",
        "\n",
        "    chrono_points = extract_key_points_chronological_clean(p[\"turns\"], top_k=12, min_score=1.0)\n",
        "    chrono_text = format_extractive_points_chronological(chrono_points)\n",
        "\n",
        "    def importance_score_text(text):\n",
        "        ssum = 0.0\n",
        "        for sent in sent_tokenize_safe(text):\n",
        "            ssum += rule_score_sentence(sent)\n",
        "        return ssum\n",
        "\n",
        "    model_score = importance_score_text(model_pred)\n",
        "    extractive_score = importance_score_text(chrono_text)\n",
        "    use_extractive = FORCE_EXTRACTIVE_PRED or (extractive_score >= model_score) or (len(model_pred.split()) < 12)\n",
        "    final_pred = chrono_text.strip() if use_extractive and chrono_text.strip() else model_pred.strip()\n",
        "    final_pred = re.sub(r\"\\n{2,}\", \"\\n\", final_pred).strip()\n",
        "\n",
        "    inference_results.append({\n",
        "        \"meeting_id\": p[\"meeting_id\"],\n",
        "        \"pred\": final_pred,\n",
        "        \"ref\": p[\"summary\"],\n",
        "        \"model_pred_raw\": model_pred,\n",
        "        \"extractive_chronological\": chrono_text,\n",
        "        \"extractive_points\": chrono_points\n",
        "    })\n",
        "\n",
        "out_inf = os.path.join(OUT_DIR,\"ami_inference_results.json\")\n",
        "with open(out_inf,\"w\",encoding=\"utf-8\") as f:\n",
        "    json.dump(inference_results, f, ensure_ascii=False, indent=2)\n",
        "print(\"Saved inference results ->\", out_inf)\n",
        "\n",
        "\n",
        "# =================== CELL 14: SAVE readable summaries & preview ===================\n",
        "safe_print_header(\"FORMATTED OUTPUTS AND SAVING\")\n",
        "try:\n",
        "    from IPython.display import display, HTML\n",
        "    html_parts=[]\n",
        "    for r in inference_results:\n",
        "        mid = r.get(\"meeting_id\",\"meeting\")\n",
        "        pred = r.get(\"pred\",\"\").strip()\n",
        "        ref = r.get(\"ref\",\"\").strip()\n",
        "        chrono = r.get(\"extractive_chronological\",\"\").strip()\n",
        "        print(f\"SAMPLE MEETING: {mid}\\n\")\n",
        "        print(\"CHRONOLOGICAL IMPORTANT POINTS (speaker -> text):\\n\")\n",
        "        print(chrono if chrono else \"(none extracted)\")\n",
        "        print(\"\\n---\\n\")\n",
        "        print(f\"PRED (final):\\n{pred}\\n\")\n",
        "        print(f\"REF (ground-truth):\\n{ref}\\n\")\n",
        "        print(\"-\"*100)\n",
        "        safe_name = \"\".join([c if c.isalnum() or c in \"-_.\" else \"_\" for c in str(mid)])\n",
        "        txt_path = os.path.join(TEXT_SUM_DIR, f\"summary_{safe_name}_important.txt\")\n",
        "        with open(txt_path,\"w\",encoding=\"utf-8\") as tf:\n",
        "            tf.write(\"CHRONOLOGICAL IMPORTANT POINTS (speaker -> text)\\n\\n\")\n",
        "            tf.write(chrono + \"\\n\\n\")\n",
        "            tf.write(\"PRED (final):\\n\" + pred + \"\\n\\n\")\n",
        "            tf.write(\"REF (ground-truth):\\n\" + ref + \"\\n\")\n",
        "        rel = os.path.relpath(txt_path, start=\"/content\")\n",
        "        link = f'<a href=\"/{rel}\" download>Download text</a>'\n",
        "        preview_html = f\"<h4>Meeting: {mid} — {link}</h4><pre style='white-space:pre-wrap;background:#f6f6f6;padding:8px;border-radius:6px'><strong>CHRONOLOGICAL IMPORTANT POINTS:</strong>\\n{chrono}\\n\\n<strong>PRED:</strong>\\n{pred}\\n\\n<strong>REF:</strong>\\n{ref}</pre>\"\n",
        "        html_parts.append(preview_html)\n",
        "    display(HTML(\"<div style='font-family:sans-serif'>\" + \"\\n<hr/>\\n\".join(html_parts) + \"</div>\"))\n",
        "    print(\"Saved chronological text summaries to:\", TEXT_SUM_DIR)\n",
        "except Exception as e:\n",
        "    print(\"HTML preview failed:\", e)\n",
        "    print(\"Saved text files to:\", TEXT_SUM_DIR)\n",
        "# =================== CELL 15: Zip LoRA (if present) & done ===================\n",
        "safe_print_header(\"EXPORT LoRA IF EXISTS\")\n",
        "if os.path.exists(LORE_DIR):\n",
        "    zip_path=os.path.join(OUT_DIR,\"flan_t5_lora_ami.zip\")\n",
        "    if os.path.exists(zip_path): os.remove(zip_path)\n",
        "    shutil.make_archive(os.path.join(OUT_DIR,\"flan_t5_lora_ami\"), 'zip', LORE_DIR)\n",
        "    print(\"Created LoRA zip ->\", zip_path)\n",
        "else:\n",
        "    print(\"No LoRA dir present at:\", LORE_DIR)\n",
        "\n",
        "safe_print_header(\"DONE\")\n",
        "print(\"Outputs (JSON, text files) are in:\", OUT_DIR)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y1nWB2B-vbaJ",
        "outputId": "ef2da2be-f1fe-4a04-80b3-567ddc66695d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USER PATHS:\n",
            "AMI_ZIP: /content/ami_public_manual_1.6.2.zip\n",
            "AMI_ROOT: /content/ami_corpus_manual\n",
            "OUT_DIR: /content/ami_project_out\n",
            "\n",
            "====== FILE CHECK & AUTO-LOCATE ======\n",
            "Trying to locate AMI files...\n",
            "Final exists -> transcript: True | abssum: True\n",
            "\n",
            "====== PARSERS ======\n",
            "\n",
            "====== BUILD PAIRS ======\n",
            "Built 1 pair from provided files.\n",
            "Saved preview -> /content/ami_project_out/ami_pairs_preview.json\n",
            "\n",
            "====== SETUP NLP DEPENDENCIES ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded SBERT on device: cpu\n",
            "\n",
            "====== EXTRACTIVE CLEANING HELPERS ======\n",
            "\n",
            "====== TOKENIZER CHUNK HELPERS ======\n",
            "\n",
            "====== EXTRACTIVE CLUSTERING (SBERT optional) ======\n",
            "\n",
            "====== PREPARE EXAMPLES ======\n",
            "Tokenizer model_max_length: 512\n",
            "Prepared 1 example(s).\n",
            "\n",
            "====== LoRA (optional) ======\n",
            "LoRA disabled by default (DO_TRAIN_LORA = False). Enable & configure if you want adapter training.\n",
            "\n",
            "====== INFERENCE & CHRONOLOGICAL EXTRACTION ======\n",
            "Using device: cpu\n",
            "\n",
            "====== RUN INFERENCE & SAVE ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "process-meetings: 100%|██████████| 1/1 [00:13<00:00, 13.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved inference results -> /content/ami_project_out/ami_inference_results.json\n",
            "\n",
            "====== FORMATTED OUTPUTS AND SAVING ======\n",
            "SAMPLE MEETING: ES2009d\n",
            "\n",
            "CHRONOLOGICAL IMPORTANT POINTS (speaker -> text):\n",
            "\n",
            "[UNK] (at ?): here we have our detailed design meeting where we will look at the prototype and right , I finally figured out what this whole second bullet point is about in my that my coach was sending to me\n",
            "[UNK] (at ?): Otherwise it's just saying I'm the secretary and I'm therefore I'm taking the minutes , s just to go just real briefly to go over minutes from last meeting , , I will open them slowly , no ?\n",
            "[UNK] (at ?): basically the moral of the story from our last minute last meeting was that we that we had meetings from we had presentations done by the Industrial Designer , or from Nathan , and Ron and from Sarah about what we can do here and what limitations we're operating with excuse me what limitations we're operating under , what risk we'd be looking at with some of the various approaches we were discussing and we essentially came to the conclusion that we should develop a remote with voice recognition , I_E_ that had a vaguely non-remote shape because you didn't really need to use it as a remote since you could just use your voice\n",
            "[UNK] (at ?): I it , yeah it's it looks a bit over budget\n",
            "[UNK] (at ?): Alright , we're in agreement on that\n",
            "[UNK] (at ?): I guess now we just go to the project evaluation which I will allow Sarah to take over\n",
            "[UNK] (at ?): I guess this is the point where we go out of role it looks and talk about our satisfaction for room for creativity and forth and how that all worked , I guess\n",
            "[UNK] (at ?): this was other costs\n",
            "[UNK] (at ?): No we've established that the costs weren't really within budget , but we could s do it We did the project evaluation based on Sarah's evaluation of on off switches and Mm\n",
            "[UNK] (at ?): Exactly I will save this into the project documents\n",
            "\n",
            "---\n",
            "\n",
            "PRED (final):\n",
            "[UNK] (at ?): here we have our detailed design meeting where we will look at the prototype and right , I finally figured out what this whole second bullet point is about in my that my coach was sending to me\n",
            "[UNK] (at ?): Otherwise it's just saying I'm the secretary and I'm therefore I'm taking the minutes , s just to go just real briefly to go over minutes from last meeting , , I will open them slowly , no ?\n",
            "[UNK] (at ?): basically the moral of the story from our last minute last meeting was that we that we had meetings from we had presentations done by the Industrial Designer , or from Nathan , and Ron and from Sarah about what we can do here and what limitations we're operating with excuse me what limitations we're operating under , what risk we'd be looking at with some of the various approaches we were discussing and we essentially came to the conclusion that we should develop a remote with voice recognition , I_E_ that had a vaguely non-remote shape because you didn't really need to use it as a remote since you could just use your voice\n",
            "[UNK] (at ?): I it , yeah it's it looks a bit over budget\n",
            "[UNK] (at ?): Alright , we're in agreement on that\n",
            "[UNK] (at ?): I guess now we just go to the project evaluation which I will allow Sarah to take over\n",
            "[UNK] (at ?): I guess this is the point where we go out of role it looks and talk about our satisfaction for room for creativity and forth and how that all worked , I guess\n",
            "[UNK] (at ?): this was other costs\n",
            "[UNK] (at ?): No we've established that the costs weren't really within budget , but we could s do it We did the project evaluation based on Sarah's evaluation of on off switches and Mm\n",
            "[UNK] (at ?): Exactly I will save this into the project documents\n",
            "\n",
            "REF (ground-truth):\n",
            "The project manager introduced the upcoming project to the team members and then the team members participated in an exercise in which they drew their favorite animal and discussed what they liked about the animal. The project manager talked about the project finances and selling prices. The team then discussed various features to consider in making the remote. The industrial designer will work on the working design of the remote. The user interface designer will work on the technical functions of the remote. The marketing executive will work on what requirements the remote has to fulfill The remote will sell for 25 Euro. The remote will be sold on an international scale. The production costs cannot exceed 12.50 Euro. Whether the remote will be used exclusively for televisions.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='font-family:sans-serif'><h4>Meeting: ES2009d — <a href=\"/ami_project_out/ami_summaries_txt/summary_ES2009d_important.txt\" download>Download text</a></h4><pre style='white-space:pre-wrap;background:#f6f6f6;padding:8px;border-radius:6px'><strong>CHRONOLOGICAL IMPORTANT POINTS:</strong>\n",
              "[UNK] (at ?): here we have our detailed design meeting where we will look at the prototype and right , I finally figured out what this whole second bullet point is about in my that my coach was sending to me\n",
              "[UNK] (at ?): Otherwise it's just saying I'm the secretary and I'm therefore I'm taking the minutes , s just to go just real briefly to go over minutes from last meeting , , I will open them slowly , no ?\n",
              "[UNK] (at ?): basically the moral of the story from our last minute last meeting was that we that we had meetings from we had presentations done by the Industrial Designer , or from Nathan , and Ron and from Sarah about what we can do here and what limitations we're operating with excuse me what limitations we're operating under , what risk we'd be looking at with some of the various approaches we were discussing and we essentially came to the conclusion that we should develop a remote with voice recognition , I_E_ that had a vaguely non-remote shape because you didn't really need to use it as a remote since you could just use your voice\n",
              "[UNK] (at ?): I it , yeah it's it looks a bit over budget\n",
              "[UNK] (at ?): Alright , we're in agreement on that\n",
              "[UNK] (at ?): I guess now we just go to the project evaluation which I will allow Sarah to take over\n",
              "[UNK] (at ?): I guess this is the point where we go out of role it looks and talk about our satisfaction for room for creativity and forth and how that all worked , I guess\n",
              "[UNK] (at ?): this was other costs\n",
              "[UNK] (at ?): No we've established that the costs weren't really within budget , but we could s do it We did the project evaluation based on Sarah's evaluation of on off switches and Mm\n",
              "[UNK] (at ?): Exactly I will save this into the project documents\n",
              "\n",
              "<strong>PRED:</strong>\n",
              "[UNK] (at ?): here we have our detailed design meeting where we will look at the prototype and right , I finally figured out what this whole second bullet point is about in my that my coach was sending to me\n",
              "[UNK] (at ?): Otherwise it's just saying I'm the secretary and I'm therefore I'm taking the minutes , s just to go just real briefly to go over minutes from last meeting , , I will open them slowly , no ?\n",
              "[UNK] (at ?): basically the moral of the story from our last minute last meeting was that we that we had meetings from we had presentations done by the Industrial Designer , or from Nathan , and Ron and from Sarah about what we can do here and what limitations we're operating with excuse me what limitations we're operating under , what risk we'd be looking at with some of the various approaches we were discussing and we essentially came to the conclusion that we should develop a remote with voice recognition , I_E_ that had a vaguely non-remote shape because you didn't really need to use it as a remote since you could just use your voice\n",
              "[UNK] (at ?): I it , yeah it's it looks a bit over budget\n",
              "[UNK] (at ?): Alright , we're in agreement on that\n",
              "[UNK] (at ?): I guess now we just go to the project evaluation which I will allow Sarah to take over\n",
              "[UNK] (at ?): I guess this is the point where we go out of role it looks and talk about our satisfaction for room for creativity and forth and how that all worked , I guess\n",
              "[UNK] (at ?): this was other costs\n",
              "[UNK] (at ?): No we've established that the costs weren't really within budget , but we could s do it We did the project evaluation based on Sarah's evaluation of on off switches and Mm\n",
              "[UNK] (at ?): Exactly I will save this into the project documents\n",
              "\n",
              "<strong>REF:</strong>\n",
              "The project manager introduced the upcoming project to the team members and then the team members participated in an exercise in which they drew their favorite animal and discussed what they liked about the animal. The project manager talked about the project finances and selling prices. The team then discussed various features to consider in making the remote. The industrial designer will work on the working design of the remote. The user interface designer will work on the technical functions of the remote. The marketing executive will work on what requirements the remote has to fulfill The remote will sell for 25 Euro. The remote will be sold on an international scale. The production costs cannot exceed 12.50 Euro. Whether the remote will be used exclusively for televisions.</pre></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved chronological text summaries to: /content/ami_project_out/ami_summaries_txt\n",
            "\n",
            "====== EXPORT LoRA IF EXISTS ======\n",
            "No LoRA dir present at: /content/ami_project_out/flan_t5_lora_ami\n",
            "\n",
            "====== DONE ======\n",
            "Outputs (JSON, text files) are in: /content/ami_project_out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5WixifbiwCzF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}